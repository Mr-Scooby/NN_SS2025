{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1131,
     "status": "ok",
     "timestamp": 1656581171893,
     "user": {
      "displayName": "Sandesh Hiremath",
      "userId": "13337524202662404678"
     },
     "user_tz": -120
    },
    "id": "Z1MgSSrlvsV5"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importing pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Importing a data scaler from sklearn (to scale values between 0 and 1 or -1 and 1)\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1656581288445,
     "user": {
      "displayName": "Sandesh Hiremath",
      "userId": "13337524202662404678"
     },
     "user_tz": -120
    },
    "id": "ZxY9H_8Yvybm"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "plt.rcParams['figure.figsize'] = [14, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the airline, sunspot and GDP datasets\n",
    "airline_data = pd.read_csv('./data/airline-passengers.csv')\n",
    "print(airline_data.head())\n",
    "\n",
    "sun_data = pd.read_csv('./data/Sun.csv')\n",
    "print(sun_data.head())\n",
    "\n",
    "gdp_data = pd.read_csv('./data/GDP.csv')\n",
    "print(gdp_data.head())\n",
    "\n",
    "airline_data = np.array(airline_data.iloc[:,1:2].values)\n",
    "sun_data = np.array(sun_data.iloc[:,1:2].values)\n",
    "gdp_data = np.array(gdp_data.iloc[:,1:2].values)\n",
    "print(airline_data.shape, sun_data.shape, gdp_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1656581291723,
     "user": {
      "displayName": "Sandesh Hiremath",
      "userId": "13337524202662404678"
     },
     "user_tz": -120
    },
    "id": "Joud_ZaZv2dN",
    "outputId": "4052b2fa-5c9a-4e01-a7d7-c6ace379b6c4"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "label_fontsize = 24  # 12 * 2\n",
    "title_fontsize = 32  # 16 * 2\n",
    "legend_fontsize = 20 # 10 * 2\n",
    "tick_fontsize = 20   # 10 * 2\n",
    "\n",
    "axs[0].plot(np.array(airline_data), label='Airline Passengers Data', color='royalblue')\n",
    "axs[0].set_title('Airline Passengers', fontsize=title_fontsize)\n",
    "axs[0].set_ylabel('Passengers', fontsize=label_fontsize)\n",
    "axs[0].legend(fontsize=legend_fontsize)\n",
    "axs[0].tick_params(axis='both', labelsize=tick_fontsize)\n",
    "\n",
    "axs[1].plot(np.array(sun_data), label='Sunspot Data', color='orange')\n",
    "axs[1].set_title('Sunspot Data', fontsize=title_fontsize)\n",
    "axs[1].set_ylabel('Sunspots', fontsize=label_fontsize)\n",
    "axs[1].legend(fontsize=legend_fontsize)\n",
    "axs[1].tick_params(axis='both', labelsize=tick_fontsize)\n",
    "\n",
    "axs[2].plot(np.array(gdp_data), label='GDP Data', color='green')\n",
    "axs[2].set_title('GDP Data', fontsize=title_fontsize)\n",
    "axs[2].set_ylabel('GDP', fontsize=label_fontsize)\n",
    "axs[2].set_xlabel('Time Step', fontsize=label_fontsize)\n",
    "axs[2].legend(fontsize=legend_fontsize)\n",
    "axs[2].tick_params(axis='both', labelsize=tick_fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1656581184618,
     "user": {
      "displayName": "Sandesh Hiremath",
      "userId": "13337524202662404678"
     },
     "user_tz": -120
    },
    "id": "UpE4ru2AxGUF"
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1656581186065,
     "user": {
      "displayName": "Sandesh Hiremath",
      "userId": "13337524202662404678"
     },
     "user_tz": -120
    },
    "id": "ATn4BtIoxHmV"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "def prepare_data(data, seq_length=8, batch_size=32, train_split=0.7):\n",
    "    sc = MinMaxScaler()\n",
    "    data_scaled = sc.fit_transform(data)\n",
    "    x, y = sliding_windows(data_scaled, seq_length)\n",
    "    train_size = int(len(y) * train_split)\n",
    "    \n",
    "    trainX = torch.Tensor(x[:train_size])\n",
    "    trainY = torch.Tensor(y[:train_size])\n",
    "    testX = torch.Tensor(x[train_size:])\n",
    "    testY = torch.Tensor(y[train_size:])\n",
    "    \n",
    "    train_dataset = TensorDataset(trainX, trainY)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return trainX, trainY, testX, testY, train_dataset, train_loader, sc\n",
    "\n",
    "# Prepare data for airline\n",
    "airline_trainX, airline_trainY, airline_testX, airline_testY, airline_train_dataset, airline_train_loader, airline_sc = prepare_data(airline_data)\n",
    "\n",
    "# Prepare data for sun\n",
    "sun_trainX, sun_trainY, sun_testX, sun_testY, sun_train_dataset, sun_train_loader, sun_sc = prepare_data(sun_data)\n",
    "\n",
    "# Prepare data for gdp\n",
    "gdp_trainX, gdp_trainY, gdp_testX, gdp_testY, gdp_train_dataset, gdp_train_loader, gdp_sc = prepare_data(gdp_data)\n",
    "\n",
    "# Combine all three train datasets\n",
    "all_train_dataset = ConcatDataset([airline_train_dataset, sun_train_dataset, gdp_train_dataset])\n",
    "all_train_loader = DataLoader(all_train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define RNN\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # RNN layer\n",
    "        # Implementing RNN cell from scratch\n",
    "        self.W_ih = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.W_hh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_ih = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        self.b_hh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Initialize parameters\n",
    "        for param in [self.W_ih, self.W_hh, self.b_ih, self.b_hh]:\n",
    "          if param.dim() > 1:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "          else:\n",
    "            nn.init.zeros_(param)\n",
    "\n",
    "        # Linear layer\n",
    "        self.fc = nn.Linear(self.hidden_size, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial hidden state\n",
    "        # x shape: (batch, seq_length, input_size)\n",
    "        # Task1: Implment an RNN cell \n",
    "        \n",
    "        out = self.fc(h_t.squeeze())\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1656581188398,
     "user": {
      "displayName": "Sandesh Hiremath",
      "userId": "13337524202662404678"
     },
     "user_tz": -120
    },
    "id": "GIMc5lO_xIyN"
   },
   "outputs": [],
   "source": [
    "# GRU model\n",
    "class GRU(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(GRU, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Implementing GRU cell from scratch\n",
    "        self.W_z = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_z = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_z = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        self.W_r = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_r = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_r = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        self.W_h = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
    "        self.U_h = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        \n",
    "        # Linear layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # Initialize parameters\n",
    "        for param in self.parameters():\n",
    "            if param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            else:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_length, input_size)\n",
    "        # Task2: Implement a GRU cell\n",
    "\n",
    "        out = self.fc(h_t.squeeze())\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 4632,
     "status": "ok",
     "timestamp": 1656581194237,
     "user": {
      "displayName": "Sandesh Hiremath",
      "userId": "13337524202662404678"
     },
     "user_tz": -120
    },
    "id": "b_7Cp75lxLNs",
    "outputId": "6a57bf9f-65fc-48df-8e00-733fd404d169"
   },
   "outputs": [],
   "source": [
    "# Training of  the gru units\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 6\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "\n",
    "def train_model(model, train_loader):\n",
    "    criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # Train the model\n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for X, Y in train_loader:\n",
    "            outputs = model(X)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * X.size(0)\n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch: %d, loss: %1.5f\" % (epoch, epoch_loss))\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GRU(num_classes, input_size, hidden_size, num_layers)\n",
    "gru_loss = train_model(gru,all_train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(num_classes, input_size, hidden_size, num_layers)\n",
    "rnn_loss = train_model(rnn, all_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(gru_loss, '-+', lw=2, label='GRU Loss', color='crimson')\n",
    "plt.plot(rnn_loss, '-+', lw=2, label='RNN Loss', color='royalblue')\n",
    "plt.xlabel('Epoch', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "plt.title('Training Loss: GRU vs RNN', fontsize=title_fontsize)\n",
    "plt.legend(fontsize=legend_fontsize)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tick_params(axis='both', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1656581194797,
     "user": {
      "displayName": "Sandesh Hiremath",
      "userId": "13337524202662404678"
     },
     "user_tz": -120
    },
    "id": "E_CYxqFGxPnl",
    "outputId": "fd265903-5d49-4853-acc5-d24851a00bcf"
   },
   "outputs": [],
   "source": [
    "# Set models to evaluation mode\n",
    "gru.eval()\n",
    "rnn.eval()\n",
    "\n",
    "# Helper function to get predictions and inverse transform\n",
    "def get_predictions(model, X, scaler):\n",
    "    with torch.no_grad():\n",
    "        pred = model(X).data.numpy()\n",
    "    pred = pred.reshape(-1, pred.shape[-1])\n",
    "    return scaler.inverse_transform(pred)\n",
    "\n",
    "def get_actual(Y, scaler):\n",
    "    return scaler.inverse_transform(Y.data.numpy().reshape(-1, Y.shape[-1]))\n",
    "\n",
    "# Airline\n",
    "airline_X_full = torch.cat([airline_trainX, airline_testX], dim=0)\n",
    "airline_gru_pred_full = get_predictions(gru, airline_X_full, airline_sc)\n",
    "airline_rnn_pred_full = get_predictions(rnn, airline_X_full, airline_sc)\n",
    "\n",
    "# Sunspot\n",
    "sun_X_full = torch.cat([sun_trainX, sun_testX], dim=0)\n",
    "sun_gru_pred_full = get_predictions(gru, sun_X_full, sun_sc)\n",
    "sun_rnn_pred_full = get_predictions(rnn, sun_X_full, sun_sc)\n",
    "\n",
    "# GDP\n",
    "gdp_X_full = torch.cat([gdp_trainX, gdp_testX], dim=0)\n",
    "gdp_gru_pred_full = get_predictions(gru, gdp_X_full, gdp_sc)\n",
    "gdp_rnn_pred_full = get_predictions(rnn, gdp_X_full, gdp_sc)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 7))\n",
    "# Airline\n",
    "airline_actual = airline_sc.inverse_transform(np.concatenate([airline_trainY, airline_testY], axis=0).reshape(-1, 1))\n",
    "axs[0].axvline(len(airline_trainY), color='gray', linestyle='--', linewidth=4, label='Test Start')\n",
    "axs[0].plot(airline_actual, color='black', label='Ground truth', linewidth=2)\n",
    "axs[0].plot(airline_gru_pred_full, color='crimson', label='GRU Prediction', linewidth=2)\n",
    "axs[0].plot(airline_rnn_pred_full, color='royalblue', label='RNN Prediction', linewidth=2)\n",
    "axs[0].set_title('Airline Passengers', fontsize=title_fontsize)\n",
    "axs[0].set_xlabel('Time Step', fontsize=tick_fontsize)\n",
    "axs[0].set_ylabel('Passengers', fontsize=tick_fontsize)\n",
    "axs[0].legend(fontsize=legend_fontsize)\n",
    "axs[0].grid(True, alpha=0.3)\n",
    "axs[0].tick_params(axis='both', labelsize=tick_fontsize)\n",
    "\n",
    "# Sunspot\n",
    "sun_actual = sun_sc.inverse_transform(np.concatenate([sun_trainY, sun_testY], axis=0).reshape(-1, 1))\n",
    "axs[1].axvline(len(sun_trainY), color='gray', linestyle='--', linewidth=4, label='Test Start')\n",
    "axs[1].plot(sun_actual, color='black', label='Ground truth', linewidth=2)\n",
    "axs[1].plot(sun_gru_pred_full, color='crimson', label='GRU Prediction', linewidth=2)\n",
    "axs[1].plot(sun_rnn_pred_full, color='royalblue', label='RNN Prediction', linewidth=2)\n",
    "axs[1].set_title('Sunspot Data', fontsize=title_fontsize)\n",
    "axs[1].set_xlabel('Time Step', fontsize=tick_fontsize)\n",
    "axs[1].set_ylabel('Sunspots', fontsize=tick_fontsize)\n",
    "axs[1].legend(fontsize=legend_fontsize)\n",
    "axs[1].grid(True, alpha=0.3)\n",
    "axs[1].tick_params(axis='both', labelsize=tick_fontsize)\n",
    "\n",
    "# GDP\n",
    "gdp_actual = gdp_sc.inverse_transform(np.concatenate([gdp_trainY, gdp_testY], axis=0).reshape(-1, 1))\n",
    "axs[2].axvline(len(gdp_trainY), color='gray', linestyle='--', linewidth=4, label='Test Start')\n",
    "axs[2].plot(gdp_actual, color='black', label='Ground truth', linewidth=2)\n",
    "axs[2].plot(gdp_gru_pred_full, color='crimson', label='GRU Prediction', linewidth=2)\n",
    "axs[2].plot(gdp_rnn_pred_full, color='royalblue', label='RNN Prediction', linewidth=2)\n",
    "axs[2].set_title('GDP Data', fontsize=title_fontsize)\n",
    "axs[2].set_xlabel('Time Step', fontsize=tick_fontsize)\n",
    "axs[2].set_ylabel('GDP', fontsize=tick_fontsize)\n",
    "axs[2].legend(fontsize=legend_fontsize)\n",
    "axs[2].grid(True, alpha=0.3)\n",
    "axs[2].tick_params(axis='both', labelsize=tick_fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOb2ylxlj8vZor6/lXZL0Ek",
   "collapsed_sections": [],
   "name": "RNN_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
